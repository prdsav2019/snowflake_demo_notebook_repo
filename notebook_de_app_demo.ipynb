{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06060903-e0b5-4970-be4d-799d5e7ba52f",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "# Project Overview\n\nPerform data analysis and data preparation tasks to train a Linear Regression model to predict future ROI (Return On Investment) of variable ad spend budgets across multiple channels including search, video, social media, and email using Snowpark for Python, Snowpark ML and Streamlit. By the end of the session, you will have an interactive web application deployed visualizing the ROI of different allocated advertising spend budgets.\n\n## Data Engineering -- Data Analysis and Data Preparation\n\nIn this Notebook, we will focus on Data Engineering in Snowflake using Snowpark for Python.\n\n- Load data from Snowflake tables into Snowpark DataFrames\n- Perform Exploratory Data Analysis on Snowpark DataFrames\n- Pivot and Join data from multiple tables using Snowpark DataFrames\n- Demostrate how to automate data preparation using Snowflake Tasks\n- For environment setup including loading data into Snowflake tables, and step-by-step instructions, please refer to the [QuickStart Guide](https://quickstarts.snowflake.com/guide/getting_started_with_dataengineering_ml_using_snowpark_python/index.html#0)."
  },
  {
   "cell_type": "markdown",
   "id": "75978241-4905-406c-a0c2-208bbcdbf2ad",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "## Import Libraries"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "from snowflake.snowpark.session import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import month,year,col,sum\nfrom snowflake.snowpark.version import VERSION\nfrom snowflake.core import Root\nfrom snowflake.core.task import Task, StoredProcedureCall\nfrom snowflake.core.task.dagv1 import DAG, DAGTask, DAGOperation\nfrom snowflake.core import CreateMode\n\n# Misc\nfrom datetime import timedelta\nimport json\nimport logging \nlogger = logging.getLogger(\"snowflake.snowpark.session\")\nlogger.setLevel(logging.ERROR)\n\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "acf35526-e031-44fe-8ced-5725a051f154",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "## Load Aggregated Campaign Spend Data from Snowflake table into Snowpark DataFrame\n\nLet's first load the campaign spend data. This table contains ad click data that has been aggregated to show daily spend across digital ad channels including search engines, social media, email and video.\n\nNote: Some other ways to load data in a Snowpark DataFrame\n\n- session.sql(\"select col1, col2... from tableName\")\n- session.read.options({\"field_delimiter\": \",\", \"skip_header\": 1}).schema(user_schema).csv(\"@mystage/testCSV.csv\")\n- session.read.parquet(\"@stageName/path/to/file\")\n- session.create_dataframe([1,2,3], schema=[\"col1\"])\n\nTIP: Learn more about [Snowpark DataFrames](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/dataframe)."
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "snow_df_spend = session.table('campaign_spend')\nsnow_df_spend.queries",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "429243f4-d59a-43fd-b787-7bed1207729a",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "Actions like show(), collect(), count() send the DataFrame SQL for execution on the server\n\nNote: History object provides the query ID which can be helpful for debugging as well as the SQL query executed on the server."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "with session.query_history() as history:\n    snow_df_spend.show(20)\nhistory.queries",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "388f6cae-b2ea-4db5-b948-62f745e5853d",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## Total Spend per Year and Month For All Channels\n\nLet's transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions.\n\nTIP: For a full list of functions, refer to the [documentation](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/functions)."
  },
  {
   "cell_type": "code",
   "id": "dc22a0e7-83ca-470c-8430-60b5f9e1e4c1",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Stats per Month per Channel\nsnow_df_spend_per_channel = snow_df_spend.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n    with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n\nsnow_df_spend_per_channel.show(10)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b9a17f7-f557-4321-b318-4068c98cc68e",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "## Pivot on Channel: Total Spend Across All Channels\n\nLet's further transform the campaign spend data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions. This transformation will enable us to join with the revenue table such that we will have our input features and target variable in a single table for model training.\n\nTIP: For a full list of functions, refer to the [documentation](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/functions)."
  },
  {
   "cell_type": "code",
   "id": "813b07ec-cf73-44dd-bbf0-261268f73d8e",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "snow_df_spend_per_month = snow_df_spend_per_channel.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\nsnow_df_spend_per_month = snow_df_spend_per_month.select(\n    col(\"YEAR\"),\n    col(\"MONTH\"),\n    col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n    col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n    col(\"'video'\").as_(\"VIDEO\"),\n    col(\"'email'\").as_(\"EMAIL\")\n)\nsnow_df_spend_per_month.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "16abb4e0-4a66-415b-99b0-a12863906fbb",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "## Save Transformed Data into Snowflake Table\n\nLet's save the transformed data into a Snowflake table SPEND_PER_MONTH."
  },
  {
   "cell_type": "code",
   "id": "bd9caea2-4825-4f86-bec7-80b3d9d07103",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "snow_df_spend_per_month.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8a2e164-b2ba-44a0-9ace-fcb2503f27ac",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "## Automation: Run Campaign Spend Data Transformations As a Snowflake Task\n\nNote: Optionally you can run all these transformations as an automated task by deploying the code to Snowflake as a Snowpark Stored Procedure and executing it as a Snowflake Task.\n\nTIP: Learn more about [Stored Procedures](https://docs.snowflake.com/en/sql-reference/stored-procedures-python) and [Snowflake Tasks](https://docs.snowflake.com/en/sql-reference/sql/create-task)."
  },
  {
   "cell_type": "code",
   "id": "6f01b5c4-3f5b-4384-9051-e15ded939c48",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def campaign_spend_data_pipeline(session: Session) -> str:\n  # DATA TRANSFORMATIONS\n  # Perform the following actions to transform the data\n\n  # Load the campaign spend data\n  snow_df_spend_t = session.table('campaign_spend')\n\n  # Transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions\n  snow_df_spend_per_channel_t = snow_df_spend_t.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n      with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n\n  # Transform the data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions\n  snow_df_spend_per_month_t = snow_df_spend_per_channel_t.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n  snow_df_spend_per_month_t = snow_df_spend_per_month_t.select(\n      col(\"YEAR\"),\n      col(\"MONTH\"),\n      col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n      col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n      col(\"'video'\").as_(\"VIDEO\"),\n      col(\"'email'\").as_(\"EMAIL\")\n  )\n\n  # Save transformed data\n  snow_df_spend_per_month_t.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c7035a7-3609-402b-8da6-8104cb7b748e",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Register data pipeline function as a task\nroot = Root(session)\nmy_task = Task(name='campaign_spend_data_pipeline_task'\n               , definition=StoredProcedureCall(\n                   campaign_spend_data_pipeline, stage_location='@dash_sprocs'\n               )\n               , warehouse='DASH_S'\n               , schedule=timedelta(minutes=3))\n\ntasks = root.databases[session.get_current_database()].schemas[session.get_current_schema()].tasks\ntask_res = tasks.create(my_task,mode=CreateMode.or_replace)\n\n# By default a Task is suspended and we need to resume it if we want it run based on the schema. Note that we can still execute a task by calling the execute method.\ntask_res.execute()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "155beaf3-16bd-489f-a1ce-538181dbf0b6",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "## Total Revenue per Year And Month\n\nNow let's load revenue table and transform the data into revenue per year/month using group_by() and agg() functions."
  },
  {
   "cell_type": "code",
   "id": "1d4578a9-3330-4e03-9b4f-d2eed87b052f",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "snow_df_revenue = session.table('monthly_revenue')\nsnow_df_revenue_per_month = snow_df_revenue.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\nsnow_df_revenue_per_month.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "630e468c-4781-4412-9f51-b894690d39e7",
   "metadata": {
    "name": "cell27",
    "collapsed": false
   },
   "source": "## Join Total Spend and Total Revenue per Year and Month Across All Channels\n\nNext let's join this revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training."
  },
  {
   "cell_type": "code",
   "id": "23705e14-a843-4b92-8b96-b14f9bdf2296",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false
   },
   "outputs": [],
   "source": "snow_df_spend_and_revenue_per_month = snow_df_spend_per_month.join(snow_df_revenue_per_month, [\"YEAR\",\"MONTH\"])\nsnow_df_spend_and_revenue_per_month.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a19f2ef7-c6d7-4d73-9d31-987da24b0f36",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "## Examine Snowpark DataFrame Query and Execution Plan\n\nSnowpark makes is really convenient to look at the DataFrame query and execution plan using explain() Snowpark DataFrame function."
  },
  {
   "cell_type": "code",
   "id": "186edbc9-d878-4ec9-a03f-d694ab9b0494",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "snow_df_spend_and_revenue_per_month.explain()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d18128c0-1c16-4710-be99-909329d418d3",
   "metadata": {
    "name": "cell29",
    "collapsed": false
   },
   "source": "## Save Transformed Data into Snowflake Table\n\nLet's save the transformed data into a Snowflake table SPEND_AND_REVENUE_PER_MONTH."
  },
  {
   "cell_type": "code",
   "id": "e8d3d424-ec65-4120-9dfc-0da0a21b5289",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "snow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "37b86074-4332-4d6b-9314-44e93964a282",
   "metadata": {
    "name": "cell30",
    "collapsed": false
   },
   "source": "## Automation: Run Monthly Revenue Data Transformations As a Snowflake Task (DAG)\n\nNote: Optionally you can run all these transformations as an automated task by deploying the code to Snowflake as a Snowpark Stored Procedure and executing it as a Snowflake Task. By using a DAG we can run it AFTER campaign_spend_data_pipeline_task.\n\nTIP: Learn more about [Stored Procedures](https://docs.snowflake.com/en/sql-reference/stored-procedures-python) and [Snowflake Tasks](https://docs.snowflake.com/en/sql-reference/sql/create-task)."
  },
  {
   "cell_type": "code",
   "id": "db9ffcd9-ce7d-425a-86e4-21b42f9655cc",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def monthly_revenue_data_pipeline(session: Session) -> str:\n  # Load revenue table and transform the data into revenue per year/month using group_by and agg() functions\n  snow_df_spend_per_month_t = session.table('spend_per_month')\n  snow_df_revenue_t = session.table('monthly_revenue')\n  snow_df_revenue_per_month_t = snow_df_revenue_t.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n\n  # Join revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training\n  snow_df_spend_and_revenue_per_month_t = snow_df_spend_per_month_t.join(snow_df_revenue_per_month_t, [\"YEAR\",\"MONTH\"])\n\n  # SAVE in a new table for the next task\n  snow_df_spend_and_revenue_per_month_t.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dcb56324-fe90-47e5-bf8c-330da47e38cf",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "Note: Since monthly_revenue_data_pipeline is depened on that campaign_spend_data_pipeline is executed first we want to create a DAG to make sure they run in the correct order."
  },
  {
   "cell_type": "code",
   "id": "a6892443-055b-4cc3-9b12-5ea58a15f3d8",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Delete the previous task\ntask_res.delete()\n\nwith DAG(\"de_pipeline_dag\", schedule=timedelta(minutes=3)) as dag:\n    # Create a task that runs our first pipleine\n    dag_spend_task = DAGTask(name='campaign_spend_data_pipeline_task'\n                        , definition=StoredProcedureCall(\n                                    campaign_spend_data_pipeline, stage_location='@dash_sprocs'\n                                )\n                        ,warehouse='DASH_S'\n                        )\n    # Create a task that runs our second pipleine\n    dag_revenue_task = DAGTask(name='monthly_revenue_data_pipeline'\n                          , definition=StoredProcedureCall(\n                                monthly_revenue_data_pipeline, stage_location='@dash_sprocs'\n                            )\n                        ,warehouse='DASH_S'\n                        )\n# Shift right and left operators can specify task relationships.\ndag_spend_task >> dag_revenue_task  # dag_spend_task is a predecessor of dag_revenue_task\n\nschema = root.databases[session.get_current_database()].schemas[session.get_current_schema()]\ndag_op = DAGOperation(schema)\n\ndag_op.deploy(dag,mode=CreateMode.or_replace)\n\n# A DAG is not suspended by default so we will suspend the root task that will suspend the full DAG\nroot_task = tasks[\"DE_PIPELINE_DAG\"]\nroot_task.suspend()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7aac0fb4-3a27-4800-bbd2-72a39fb264ea",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "## Run DAG\n\nNote that we can manually run DAGs even if they are suspended"
  },
  {
   "cell_type": "code",
   "id": "ab79fde1-28e2-41e2-a3bd-4377d392c13e",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# dag_op.run(dag)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd0fa7d5-b026-43e4-aefd-d4ae259e8b23",
   "metadata": {
    "name": "cell33",
    "collapsed": false
   },
   "source": "## Resume DAG"
  },
  {
   "cell_type": "code",
   "id": "6d53b663-04bd-4f3f-9adb-7f722087c6b5",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "# root_task = tasks[\"DE_PIPELINE_DAG\"]\n# root_task.resume()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8d165ce-eb80-4e71-ac82-4618e8ab7f37",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "## Suspend Tasks\n\nNote: For the sake of this lab, if you resume the above tasks, suspend them to avoid unecessary resource utilization by executing the following commands."
  },
  {
   "cell_type": "code",
   "id": "dbde842a-562d-430f-9ded-44fd2c7d501d",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# root_task = tasks[\"DE_PIPELINE_DAG\"]\n# root_task.suspend()",
   "execution_count": null
  }
 ]
}